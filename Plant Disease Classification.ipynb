{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mounting drive to the virtual environment (if using online colaborators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wb7BfekNEzdq",
    "outputId": "6955c703-f5ed-42e9-9b7b-16115cf34c35"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary Libraries for our task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0ftbecNFO0h",
    "outputId": "dda604b0-d094-469d-e4d4-1a76774176c9"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import __version__\n",
    "import cv2\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "#from keras.applications.Xception import Xception\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path where our train and validation datasets are in drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '/content/gdrive/MyDrive/Train'\n",
    "validation_data_path = '/content/gdrive/MyDrive/Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " function for getting number of files by searching directory recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_files(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intializing the image and batch size, And getting the number of files using the above created function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "image_size=(224,224)\n",
    "\n",
    "nb_train_samples = get_nb_files(train_data_path)\n",
    "nb_validation_samples = get_nb_files(validation_data_path)\n",
    "\n",
    "classes_num = len(glob.glob(train_data_path + \"/*\"))\n",
    "\n",
    "print(\"number of classes is :\"+str(classes_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Training and Validation Imagedatagenerators(Generate batches of tensor image data with real-time data augmentation.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                rotation_range=40,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                preprocessing_function=preprocess_input,\n",
    "                horizontal_flip=False,\n",
    "                fill_mode='nearest')\n",
    "\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_generator(train_datagen):\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "                train_data_path,\n",
    "                target_size=image_size,\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical'\n",
    "                )\n",
    "    while True:\n",
    "      Xi,Yi=train_generator.next()\n",
    "      yield Xi, [Yi, Yi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validaion_generator(validation_datagen):\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "                validation_data_path,\n",
    "                target_size=image_size,\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical'\n",
    "                ) \n",
    "    while True:\n",
    "      Xi,Yi= validation_generator.next()\n",
    "      yield Xi, [Yi, Yi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model which consists of three classifiers namely Teacher, Decoder, Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher/Student graph.\n",
    "# Teacher ---> Decoder ---> Student\n",
    "def build_graph(input_shape = (224,224,3),nbr_of_classes=13,view_summary=False):\n",
    "#Teacher's graph.\n",
    "    base_model1 = VGG16(include_top=False, weights='imagenet',input_shape = input_shape)\n",
    "    x1_0 = base_model1.output\n",
    "    x1_0 = Flatten(name='Flatten1')(x1_0)\n",
    "    x1_1 = Dense(256, name='fc1',activation='relu')(x1_0)\n",
    "    x1_2 = classif_out_encoder1 = Dense(nbr_of_classes, name='out1', activation = 'softmax')(x1_1)  \n",
    "#Decoder's graph.\t\n",
    "\t#Get Teacher's tensors for skip connection.\n",
    "    pool5 = base_model1.get_layer('block5_pool').output\n",
    "    conv5 = base_model1.get_layer('block5_conv3').output\n",
    "    conv4 = base_model1.get_layer('block4_conv3').output\n",
    "    conv3 = base_model1.get_layer('block3_conv3').output\n",
    "    conv2 = base_model1.get_layer('block2_conv2').output\n",
    "    conv1 = base_model1.get_layer('block1_conv2').output\n",
    "\t#Inverse fully connected Teacher's layers. \n",
    "    inv_x1_1 = Dense(256, name='inv_x1_1',activation='relu')(x1_2)\n",
    "    merge_x1_1 = Add(name='merge_x1_1')([inv_x1_1,x1_1])\n",
    "    inv_x1_0 = Dense(7*7*512, name='x1_1',activation='relu')(merge_x1_1)\n",
    "    reshaped_inv_x1_0 = Reshape((7, 7,512), name='')(inv_x1_0)\n",
    "    inv_x1_0 = Add(name='merge_x1_0')([reshaped_inv_x1_0,pool5])\n",
    "    #DECONV Block1\n",
    "    up7 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(inv_x1_0))\n",
    "    merge7 = concatenate([conv5,up7], axis = 3)\n",
    "    conv7 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "    #DECONV Block2\n",
    "    up8 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv4,up8], axis = 3)\n",
    "    conv8 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "    #DECONV Block13\n",
    "    up9 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv3,up9], axis = 3)\n",
    "    conv9 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #DECONV Block14\n",
    "    up10 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv9))\n",
    "    merge10 = concatenate([conv2,up10], axis = 3)\n",
    "    conv10 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge10)\n",
    "    conv10 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv10)\n",
    "\t#DECONVBlock15\n",
    "    up11 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv10))\n",
    "    merge11 = concatenate([conv1,up11], axis = 3)\n",
    "    conv11 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge11)\n",
    "    conv11 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv11)\n",
    "    #Reconstructed image refinement\n",
    "    conv11 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv11)\n",
    "    mask = conv11 = Conv2D(3, 1, activation = 'sigmoid',name='Mask')(conv11)\n",
    "    \n",
    "#Graphe of Student\n",
    "    base_model2 = VGG16(include_top=False, weights='imagenet',input_shape = (224,224,3))\n",
    "    x2_0 = base_model2(mask)\n",
    "    x2_0 = Flatten(name='Flatten2')(x2_0)\n",
    "    x2_1 = Dense(256, name='fc2',activation='relu')(x2_0)\n",
    "    classif_out_encoder2  = Dense(nbr_of_classes, name='out2',activation='softmax')(x2_1)\n",
    " \n",
    "#Get Teacher/Student Model\n",
    "    model = Model(base_model1.input, [classif_out_encoder1,classif_out_encoder2])\n",
    "    if(view_summary):\n",
    "\t    print(model.summary())\n",
    "#Compile the mode to use multi-task learning\n",
    "    losses = {\n",
    "            \"out1\": 'categorical_crossentropy',\n",
    "            \"out2\": 'categorical_crossentropy',\n",
    "            }\n",
    "    alpha=0.4\n",
    "    lossWeights = {\"out1\": alpha, \"out2\": (1.0-alpha)}\n",
    "    model.compile(optimizer=SGD(lr=1e-4, momentum=0.9), loss=losses, loss_weights=lossWeights,metrics = ['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intializing the number of epochs and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_graph(view_summary=True)\n",
    "\n",
    "nb_epoch = 20\n",
    "history = model.fit_generator(get_train_generator(train_datagen),\n",
    "                    epochs=nb_epoch,\n",
    "                    validation_data=get_validaion_generator(validation_datagen),\n",
    "                    steps_per_epoch=nb_train_samples//batch_size,\n",
    "                    validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model's weights for reusing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = './MyDrive/models/'\n",
    "if not os.path.exists(target_dir):\n",
    "    os.mkdir(target_dir)\n",
    "\n",
    " \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "model.save_weights('./MyDrive/models/model_weights')\n",
    "hist_csv_file = './MyDrive/models/history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TeacherStudent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
